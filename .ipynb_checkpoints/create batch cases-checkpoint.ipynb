{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "35433154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# inputs\n",
    "template_path = Path(\"./case_runner_template\")\n",
    "julia_path = Path(\"/Applications/Julia-1.8.app/Contents/Resources/julia/bin/julia\")\n",
    "destination_path = Path(\".\")\n",
    "ldes_duration_hours = 200\n",
    "rep_period_lengths = [24,168,8760]\n",
    "num_rep_periods = [5,30]\n",
    "ldes_size_mw_base = 1 # size of ldes for the most granular aggregation (will be held constant across aggregations)\n",
    "pg_output_paths = [\n",
    "    Path(\"./pg_output_3z\"),\n",
    "]\n",
    "\n",
    "# load aggregation data\n",
    "constituents = pd.read_csv(\"constituents.csv\")\n",
    "\n",
    "for path in pg_output_paths:\n",
    "    path_before_z = (str(path)).rpartition('z')[0]\n",
    "    num_zones = int(path_before_z.split(\"_\")[-1])\n",
    "    \n",
    "    # copy case runner template folder into a new folder under destination path with the same name as the PG outputs folder\n",
    "    destination_case_runner_folder = destination_path / (\"case_runner_\"+str(num_zones)+\"_zone\")\n",
    "    destination = shutil.copytree(template_path, destination_case_runner_folder)\n",
    "\n",
    "    # copy all input files from PG outputs to destination folder\n",
    "    for file in (pg_output_path / \"Inputs\").glob(\"*.csv\"):\n",
    "        shutil.copy(file,destination_case_runner_folder / \"template\")\n",
    "\n",
    "    # modify Generators_data.csv in place\n",
    "\n",
    "    generators_data = pd.read_csv(destination_case_runner_folder / \"template\" / \"Generators_data.csv\")\n",
    "\n",
    "    # drop all Hydrogen generators-- we will use the metal air technology as a \"generic LDES\"\n",
    "    generators_data.drop(index=generators_data[generators_data.technology.str.contains(\"Hydrogen\")].index,inplace=True)\n",
    "\n",
    "    metalair_rows = generators_data[generators_data.technology.str.contains(\"MetalAir\")]\n",
    "    for index in metalair_rows.index:\n",
    "        zone = metalair_rows.loc[index,\"region\"]\n",
    "\n",
    "        # make LDES new build\n",
    "        generators_data.loc[index,\"New_Build\"] = 1\n",
    "\n",
    "        # specify LDES capacity\n",
    "        for capacity_param in [\"Min_Cap_MW\",\"Max_Cap_MW\",\"Min_Charge_Cap_MW\",\"Max_Charge_Cap_MW\"]:\n",
    "            generators_data.loc[index,capacity_param] = \"__SPECIAL_\"+\"LDESCapMW\"+zone+\"__\"\n",
    "\n",
    "        # change LDES cost to 0\n",
    "        for cost_param in [\"capex_mw\",\"Inv_Cost_per_MWyr\",\"Fixed_OM_Cost_per_MWyr\",\"capex_mwh\",\"Inv_Cost_per_MWhyr\"]:\n",
    "            generators_data.loc[index,cost_param] = 0\n",
    "\n",
    "        # fix LDES duration\n",
    "        for duration_param in [\"Min_Duration\",\"Max_Duration\"]:\n",
    "            generators_data.loc[index,duration_param] = ldes_duration_hours\n",
    "\n",
    "    generators_data.to_csv(destination_case_runner_folder / \"template\" / \"Generators_data.csv\",index=False)\n",
    "\n",
    "    # make replacements.csv\n",
    "\n",
    "    replacements = pd.DataFrame()\n",
    "    constituents_cur = constituents[constituents.Aggregation==num_zones][[\"Zone\",\"Constituents\"]].set_index(\"Zone\").Constituents\n",
    "\n",
    "    for length in rep_period_lengths:\n",
    "        for num_periods in num_rep_periods:\n",
    "            for incl_ldes in [1,0]:\n",
    "\n",
    "                if (length != 8760) and (num_periods * length >= 8760):\n",
    "                    continue\n",
    "\n",
    "                if length == 8760:\n",
    "                    replacements_cur = pd.DataFrame(data=dict(UseTimeDomainReduction=[0],RepPeriodLengthHours=[0],NumRepPeriods=[0]))\n",
    "                else:\n",
    "                    replacements_cur = pd.DataFrame(data=dict(UseTimeDomainReduction=[1],RepPeriodLengthHours=[length],NumRepPeriods=[num_periods]))\n",
    "\n",
    "                for zone in constituents_cur.index:\n",
    "                    # LDES capacity = number of constituents * size in granular aggregation * boolean for including ldes\n",
    "                    replacements_cur[\"LDESCapMW\"+zone] = constituents_cur.loc[zone] * ldes_size_mw_base * incl_ldes\n",
    "                replacements = pd.concat([replacements,replacements_cur],axis=0,ignore_index=True)\n",
    "\n",
    "    replacements.drop_duplicates(inplace=True)\n",
    "    replacements[\"Notes\"] = \"\"\n",
    "    replacements.index.name=\"Case\"\n",
    "    replacements.index = replacements.index + 1\n",
    "\n",
    "    replacements.to_csv(destination_case_runner_folder / \"replacements.csv\",index=True)\n",
    "\n",
    "    # run julia code\n",
    "    os.chdir(destination_case_runner_folder)\n",
    "    output = subprocess.run([julia_path, \"caserunner.jl\"])\n",
    "    os.chdir(\"..\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
